\documentclass[dvipdfmx,autodetect-engine]{jsarticle}


\usepackage[utf8]{inputenc}
\usepackage{amsmath}
\usepackage{amsthm}
\usepackage{amssymb}
\usepackage{mathtools}

\usepackage[dvipdfmx]{graphicx}

\newtheorem{theorem}{Theorem}[section]
\newtheorem{corollary}{Corollary}[theorem]
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{example}{Example}[section]

\theoremstyle{remark}
\newtheorem*{remark}{Remark}

\theoremstyle{definition}
\newtheorem{definition}{Definition}[section]

\mathtoolsset{showonlyrefs}

\renewcommand{\labelenumi}{(\arabic{enumi})}
\renewcommand{\labelenumii}{(\alph{enumii}}
\newcommand{\R}{\mathbb{R}}
\newcommand{\N}{\mathbb{N}}
\newcommand{\C}{\mathbb{C}}
\newcommand{\Z}{\mathbb{Z}}


\begin{document}

\title{マルコフ連鎖の基本}
\author{@litharge3141}
\date{\today}
\maketitle

\section{マルコフ連鎖の基本}
有限ないし高々可算の状態空間を持ち，かつ離散的という最もシンプルな場合を通して，
マルコフ過程の概念を整理する．大数の強法則を証明したことがある程度の知識を仮定する．
本文全体を通して$I$を高々可算集合とし，その$\sigma$-代数として
$I$の部分集合全体$\mathcal{P}(I)$を取る．また，自然数の全体$\N$は$0$を含むものとする．
\subsection{マルコフ連鎖の定義}
時間変化する確率変数は，各時刻で$I$上の確率分布を与える．
それが時間無限大でどうなるかとか，そういう問題を考えたい．
$I$は高々可算だから，$I$上の分布はうまく言い換えられる．


\begin{definition}
    写像$\nu \colon I \to [0,1]$が確率ベクトルであるとは，$\sum_{i\in I} \nu (i)=1$
    が成立することをいう．$\nu$を$(\nu_i)_{i\in I}$ともかき，$\nu(i)$を単に$\nu_i$とかく．
    写像$A\colon I\times I \to [0,1]$が確率行列であるとは，任意の$i\in I$に対して，
    $\sum_{j\in I} A(i,j) = 1$が成立することをいう．$A$を$(A_{ij})_{i,j\in I}$ともかき，
    $A(i,j)$を単に$A_{ij}$とかく．
\end{definition}


確率ベクトル$\nu$に対して$P\colon\mathcal{P}(I) \to [0,1]$を$P(E) \coloneqq \sum_{i \in E} \nu_i$により
定めると，$P$は$I$上の確率測度となる．逆に$I$上の確率測度$P$に対して
$\nu_i \coloneqq P(\{i\})$と定めると，$\nu$は確率ベクトルになる．
したがって，$I$上の確率分布を定めることは，確率ベクトルを定めることと同じである．

\begin{example}
    $i \in I$に対して，確率ベクトル$\delta_i$を
    \begin{align}
        \delta_i (j) = 
        \begin{cases}
            1 \quad (j=i) \\
            0 \quad (j\neq i)
        \end{cases}
    \end{align}
    によって定めることができる．この記号$\delta_i$は後で用いる．
\end{example}

\begin{theorem}
    確率ベクトル$\nu$と確率行列$A$の積$\nu A \colon I \to [0,1]$を$j \in I$に対し
    $\nu A (j) \coloneqq \sum_{i \in I} \nu_i A_{ij}$によって定めることができ，$\nu A$は
    確率ベクトルになる．
    確率行列$A,B$の積$AB \colon I\times I \to [0,1]$を$AB(i,j) = \sum_{k \in I} A_{ik}B_{kj}$
    によって定めることができ，$AB$は確率行列になる．
\end{theorem}


\begin{proof}
    非負項の二重級数はいつでも和をとる順序を交換できるので，定理が従う．
\end{proof}


確率行列は確率ベクトルの変換を定めるが，これは分布の変換を定めているのと
同じことである．

\begin{example}[破産問題]
    $I = \Z$とし，$X_n$を$n$回目の試行の後の所持金とする．
    確率$1/2$で$X_{n+1}=X_{n}+1$とし，確率$1/2$で$X_{n+1}=X_{n}-1$とするような
    賭けを考える．最初の所持金を$i$とすると，初期分布は$\delta_i$で与えられる．
    この試行の確率行列は
    \begin{align}
        A_{ij} = 
        \begin{cases}
            1/2 \quad (j = i \pm 1) \\
            0 \quad (\text{それ以外}) 
        \end{cases}
    \end{align}
    によって与えられる．
\end{example}


初期分布と時間によらない分布の変換が与えられているとき，
それにしたがって発展するような分布を持つ確率変数列のことをマルコフ連鎖という．
素直に数式で表現すると次のようになる．


\begin{definition}[Markov連鎖っぽいなにか]
    確率ベクトル$\nu$と確率行列$A$が与えられたとする．
    $(\Omega,\mathcal{F},P)$を確率空間として，
    $\Omega$から$I$への確率変数列$(X_n)_{n=0}^{\infty}$が
    遷移行列$A$，初期分布$\nu$をもつマルコフ連鎖であるとは，
    任意の$E \subset I$に対して$P(X_0 \in E) = \sum_{i \in E} \nu_{i}$
    が成立し，さらに
    任意の$n\in \N$と任意の$E \subset I$に対して
    $P(X_{n+1}\in E)=\sum_{i \in E} \sum_{j \in I} P(X_n = j) A_{ji}$
    が成立することをいう．
\end{definition}


この定義は任意の$i \in I$に対して$P(X_{n+1} = i)= \sum_{j \in I} P(X_n = j) A_{ji}$
が成立すること，と書き換えてもよい．
この定義は次の定義を採用すればそれから導かれる．


\begin{definition}[Markov連鎖]
    確率ベクトル$\nu$と確率行列$A$が与えられたとする．
    $(\Omega,\mathcal{F},P)$を確率空間として，
    $\Omega$から$I$への確率変数列$(X_n)_{n=0}^{\infty}$が
    遷移行列$A$，初期分布$\nu$をもつマルコフ連鎖であるとは，
    任意の$n \in \N$と任意の$i_0,\ldots,i_{n} \in I$に対して，
    $P(X_{0} = i_{0}, X_{1}=i_{1},\ldots,X_n = i_n) = 
    \nu_{i_0} A_{i_0 i_1} A_{i_1 i_2}\cdots A_{i_{n-1} i_n}$
    が成立することをいう．マルコフ連鎖を初期分布と遷移行列，
    確率測度との組にして$((X_n)_{n=0}^{\infty},A,\nu,P)$
    と書き表すこともある．
\end{definition}


この定義は任意の$i,j \in I$に対して$P(X_0 = i)=\nu_{i}$および
$P(X_{n+1} = i \mid X_n = j)= A_{ji}$が成立すること，と書き換えてもよい．
っぽいなにかのほうだと後で証明が回らなくなるようなので，このノートではこちらの定義を採用する．
実は同値だったとか，具体的にどこがまずいのかとか分かったら追記する．
マルコフ連鎖が常に存在するかは自明ではないので，存在を示す．


\begin{theorem}\label{markov_exist}
    確率ベクトル$\nu$と確率行列$A$が与えられたとする．このとき，
    ある確率空間$(\Omega,\mathcal{F},P)$と
    $\Omega$から$I$への確率変数列$(X_n)_{n=0}^{\infty}$が
    存在して，遷移行列$A$，初期分布$\nu$をもつマルコフ連鎖となる．
\end{theorem}


\begin{proof}
    コルモゴロフの拡張定理を使うために，便宜的に$\R^n$上の確率測度を構成する．
    $I$は高々可算集合，したがって単射$\phi \colon I \to \N$が存在する．
    $n =1,2,\ldots $に対して写像$\mu_n \colon \mathcal{B}(\R^n) \to \R$
    を$\mu_n (E) \coloneqq \sum_{(\phi(i_0),\ldots,\phi(i_{n-1}) ) \in E} 
    \nu_{i_0} A_{i_0 i_1} A_{i_1 i_2} \cdots A_{i_{n-2} i_{n-1}}$
    と定めると，これは$(\R^n , \mathcal{B}(\R^n))$上の確率測度になる．
    さらに拡張定理の仮定である整合条件$\mu_{n+1}(E\times \R) = \mu_n (E)$
    が満たされることも示せるので，コルモゴロフの拡張定理から$\R^{\N}$上の
    確率測度$\mu$で任意の$n=1,2,\ldots$と任意の$A \in \mathcal{B}(\R^n)$に対して
    $\mu(A\times \R^{\N}) = \mu_n(A)$を満たすものが一意的に存在する．
    $n=1,2,\ldots$に対して$Z_n \colon\R^{\N} \to \R$を
    $n$成分への射影$Z_n((x_1,x_2,\ldots))=x_n$によって
    定めて，$n \in \N$に対して$Y_n \coloneqq Z_{n+1}$とする．
    $(Y_n)_{n=0}^{\infty}$はほとんどいたるところ$\phi(I)$に値を取る確率変数列で，
    任意の$n \in \N$と任意の$i_0,\ldots,i_{n} \in I$に対して，
    $P(Y_{0} = \phi(i_{0}), Y_{1}=\phi(i_{1}),\ldots,Y_n = \phi(i_n)) = 
    \nu_{i_0} A_{i_0 i_1} A_{i_1 i_2}\cdots A_{i_{n-1} i_n}$
    を満たす．零集合上の値を修正して$I$値にすれば，
    求めるマルコフ連鎖$(X_n)_{n=0}^{\infty}$が得られる．
\end{proof}


しばしば現れてきた$\{ \omega \mid X_0 (\omega)= i_0,\ldots, X_n (\omega)= i_n\}$
のような形の事象全体で作られる，自然な増大情報系という概念を導入しておくと便利である．


\begin{definition}
    $(\Omega,\mathcal{F},P)$を確率空間として，$\Omega$から$I$への
    確率変数列$X = (X_n)_{n=0}^{\infty}$が与えられたとする．$n \in \N$
    に対して$\mathcal{F}$の部分$\sigma$-代数$\mathcal{F}_n$を
    $\mathcal{F}_n \coloneqq \sigma (X_0,\ldots,X_n)$と定める．
    $(\mathcal{F}_n)_{n =0}^{\infty}$を$X$に関する自然な増大情報系という．
\end{definition}


$I$は高々可算集合なので，$F\subset I^n$に対して
$E = (X_0,\ldots,X_n)^{-1} (F)$という形でかける$E$は
$E = \bigcup_{(i_0,\ldots,i_n) \in F} \{X_0 = i_0,\ldots,X_n = i_n\}$
という交わらない可算和で書き直せる．このような元全体で生成されるのが$\mathcal{F}_n$
である．各時間$n$において，$X$に関連する事象で確率を計算し得るものは全てここに属する．
そのような中で最小のもの，というのが自然という言葉の意味である．

マルコフ連鎖は時刻$n+1$での確率分布が時刻$n$での分布にのみ依存するという性質を持つ．
これをマルコフ性という．それを示そう．


\begin{theorem}[マルコフ性1]
    $(\Omega,\mathcal{F},P)$を確率空間として，
    $\Omega$から$I$への確率変数列$(X_n)_{n=0}^{\infty}$は
    遷移行列$A$，初期分布$\nu$をもつマルコフ連鎖であるとする．このとき，
    $P(X_n = i_n,\ldots,X_0 = i_0) >0$が成り立つような
    任意の$n \in \N$と任意の$i_0,\ldots,i_{n+1} \in I$に対して，
    $P(X_{n+1} \mid X_n = i_n,\ldots,X_0 = i_0)=A_{i_n i_{n+1}}$が成立する．
\end{theorem}


\begin{proof}
    $n \in \N$と$i_0,\ldots,i_{n+1} \in I$が任意に与えられたとすると，
    $P(X_{n+1}=i_{n+1} \mid X_n = i_n,\ldots,X_0 = i_0)P(X_n = i_n,\ldots,X_0 = i_0) 
    = P(X_{n+1},X_n = i_n,\ldots,X_0 = i_0)$が成り立つ．$(X_n)_{n=0}^{\infty}$
    がマルコフ連鎖であるから，$P(X_n = i_n,\ldots,X_0 = i_0) = \nu_{i_0} A_{i_0 i_1} \cdots A_{i_{n-1} i_n}$
    および$P(X_{n+1},X_n = i_n,\ldots,X_0 = i_0) = \nu_{i_0} A_{i_0 i_1} \cdots A_{i_{n} i_{n+1}}$
    となる．これを代入して計算をすれば定理を得る．
\end{proof}


マルコフ性は別の定式化をすることもできる．次の性質も成り立つ．


\begin{theorem}[マルコフ性2]\label{markov_prop2}
    $(\Omega,\mathcal{F},P)$を確率空間として，
    $\Omega$から$I$への確率変数列$(X_n)_{n=0}^{\infty}$は
    遷移行列$A$，初期分布$\nu$をもつマルコフ連鎖であるとする．
    $P(X_m = i) >0$が成り立つような
    任意の$i \in I$と任意の$m \in \N$に対して，
    $Y_n \coloneqq X_{n+m}$として$(Y_n)_{n=0}^{\infty}$
    を定めると，$((Y_n)_{n=0}^{\infty},A,\delta_i, P(\cdot \mid X_m = i))$
    はマルコフ連鎖となる．
\end{theorem}


\begin{proof}
    $i \in \N$と$i_m,i_{m+1},\ldots,i_{m+n} \in I$が任意に与えられたとする．
    \begin{align}
        &P(Y_0 = i_m ,\ldots, Y_n = i_{m+n} \mid X_m = i) \\
        &= P(X_m = i,X_m = i_m,\ldots,X_{m+n}=i_{m+n}) / P(X_m = i) \\
        &= \frac{\sum_{i_0,\ldots,i_{m-1} \in I} P(X_0 = i_0,\ldots, 
        X_{m-1} = i_{m-1},X_m = i,X_m = i_m,\ldots,X_{m+n}=i_{m+n})}{\sum_{j_0,\ldots,j_{m-1} 
        \in I} P(X_0 = j_0,\ldots, X_{m-1} = j_{m-1},X_m = i)}\\
        &= \frac{\sum_{i_0,\ldots,i_{m-1} \in I} \delta_{i}(i_m) 
         \nu_{i_0} A_{i_0 i_1} \cdots A_{i_{m+n-1}{i_{m+n}}}}{\sum_{i_0,\ldots,i_{m-1} \in I} 
         \nu_{j_0} A_{j_0 j_1} \cdots A_{j_{m-1} i}} \\
        &= \delta_{i}(i_m) A_{i_{m} i_{m+1}} \cdots A_{i_{m+n-1} i_{m+n}} \frac{\sum_{i_0,\ldots,i_{m-1} \in I} 
        \nu_{i_0} A_{i_0 i_1} \cdots A_{i_{m-1} i}}{\sum_{i_0,\ldots,i_{m-1} \in I} 
        \nu_{j_0} A_{j_0 j_1} \cdots A_{j_{m-1} i}} \\
        &= \delta_{i}(i_m) A_{i_{m} i_{m+1}} \cdots A_{i_{m+n-1} i_{m+n}}
    \end{align}
    したがって，示された．
\end{proof}


$\mathrm{Theorem}\ref{markov_prop2}$を使うとより強い次の結果を示すことができる．


\begin{theorem}[$\mathcal{F}_{m}$との独立性]
    $(\Omega,\mathcal{F},P)$を確率空間として，
    $\Omega$から$I$への確率変数列$(X_n)_{n=0}^{\infty}$は
    遷移行列$A$，初期分布$\nu$をもつマルコフ連鎖であるとする．
    $P(X_m = i) >0$が成り立つような
    任意の$i \in I$と任意の$m \in \N$に対して，
    $Y_n \coloneqq X_{n+m}$として$(Y_n)_{n=0}^{\infty}$
    を定める．このとき，確率空間$(\Omega,\mathcal{F},P(\cdot \mid X_m = i))$
    の下で$(Y_n)_{n=0}^{\infty}$と$\mathcal{F}_m$は独立である．
\end{theorem}


\begin{proof}
    $n \in \N$と$j_0,j_1,\ldots,j_m,i_m,i_{m+1},\ldots,i_{m+n} \in I$
    が任意に与えられたとする．
    $E \coloneqq \{X_0 = j_0,\ldots, X_m = j_m\}$とおく．$E \in \mathcal{F}_m$
    は定義から明らかである．この$E$に対して
    \begin{align}
        &P((Y_0=i_m,\ldots,Y_n = i_{m+n})\cap E \mid X_m = i ) \\
        &= 
        P(Y_0=i_m,\ldots,Y_n = i_{m+n} \mid X_m = i) P(E \mid X_m = i) \label{Fm_indep_1}
    \end{align}
    を示す．$(X_n)_{n=0}^{\infty}$のマルコフ性から
    \begin{align}
       &P((Y_0=i_m,\ldots,Y_n = i_{m+n})\cap E \mid X_m = i )\\
        &=\delta_i(i_m) P(X_{0} = j_{0},\ldots,
        X_m = j_m,X_m = i_m,\ldots, X_{m+n}=i_{m+n}) / P(X_m = i)\\
        &=\delta_{j_m i_m} \delta_i(i_m) \nu_{j_0} A_{j_0 j_1}  \cdots A_{i_{m+n-1} i_{m+n}} / P(X_m = i)
    \end{align}
    および
    \begin{align}
        P(E \mid X_m = i) &= 
        \delta_i(j_m) P(X_0=j_0,\ldots,X_{m-1}=j_{m-1},X_m = j_m) / P(X_m = i)\\
        &= \delta_i(j_m) \nu_{j_0} A_{j_0 j_1} \cdots A_{j_{m-1} j_m} / P(X_m = i)
    \end{align}
    が得られる．また$\mathrm{Theorem}\ref{markov_prop2}$により，
    \begin{align}
        P(Y_0=i_m,\ldots,Y_n = i_{m+n} \mid X_m = i) = 
        \delta_{i}(i_m) A_{i_m i_{m+1}} \cdots A_{i_{m+n-1} i_{m+n}}
    \end{align}
    となる．これらの式から$\eqref{Fm_indep_1}$が得られた．一般の$E \in \mathcal{F}_m$
    に対して証明するため，上の結果を利用する．
    \begin{align}
        \mathcal{C} \coloneqq \{E \mid  
        &\forall n \in \N,\, \forall i_m,\ldots,i_{m+n} \in I,\,\\
        &P((Y_0=i_m,\ldots,Y_n = i_{m+n})\cap E \mid X_m = i ) \\
        &= 
        P(Y_0=i_m,\ldots,Y_n = i_{m+n} \mid X_m = i) P(E \mid X_m = i) \}
    \end{align}
    とおく．$E = \{X_0 = j_0,\ldots, X_m = j_m\}$の形で表される$E$の全体は
    $\mathcal{C}$に含まれるから，$\mathcal{C}$が$\sigma$-代数であることを
    示せばよいが，それは$P(\cdot \mid X_m = i)$が確率測度であることから
    直ちにしたがう．よって示された．
\end{proof}


\subsection{到達確率と差分作用素}
マルコフ性の応用として到達確率と差分作用素を扱う．


\begin{definition}
    $(\Omega,\mathcal{F},P)$を確率空間として，
    $\Omega$から$I$への確率変数列$(X_n)_{n=0}^{\infty}$は
    遷移行列$A$，初期分布$\nu$をもつマルコフ連鎖であるとする．
    $E \subset I$に対して，到達時刻$\tau_{E} \colon \Omega \to \N \cup \{\infty \}$を
    \begin{align}
        \tau_{E}(\omega) \coloneqq \inf\{n \in \N \mid X_n(\omega) \in E\}
    \end{align}
    によって定める．ただし，$\inf \emptyset \coloneqq \infty$とする．
\end{definition}


\begin{theorem}
    $(\Omega,\mathcal{F},P)$を確率空間として，
    $\Omega$から$I$への確率変数列$(X_n)_{n=0}^{\infty}$は
    遷移行列$A$，初期分布$\nu$をもつマルコフ連鎖であるとする．
    任意の$E \subset I$に対して，到達時刻$\tau_{E}$は
    $\N \cup \{\infty \}$の部分集合全体を$\sigma$-代数として
    可測であり，さらに任意の$n \in \N$に対して
    $\{\tau_{E} = n\} \in \mathcal{F}_n$となる．
\end{theorem}

\begin{proof}
    $\N \cup \{ \infty\}$は可算集合だから，
    $\tau_{E}$による一点集合の引き戻しが可測であることを示せば十分である．
    $\{\tau_{E} = \infty \} = \bigcap_{n\in \N} X_n^{-1} (E^{c})$
    は明らかに可測集合である．
    $n \in \N$が任意に与えられたとして，
    $\{\tau_{E} = n \} \in \mathcal{F}_n$を示す．
    $E$および$E^c$は高々可算集合だから，値で場合分けをして
    \begin{align}
        \{\tau_{E} = n\} &= 
        \bigcup_{i_0 \in E^{c} ,\ldots, i_{n-1} \in E^{c},i_n \in E}
        \{X_0 = i_0,\ldots, X_n = i_n\} 
    \end{align}
    となる．したがって$\{\tau_{E} = n\} \in \mathcal{F}_n$である．
\end{proof}


\begin{definition}
    確率行列$A$と$E \subset I$が与えられたとする．
    マルコフ連鎖の$E$への到達確率$e\colon I \to \R$を，
    $i \in I$に対して，初期分布$\delta_i$，遷移行列$A$
    を持つ任意のマルコフ連鎖$(X,A,\delta_{i},P)$を用いて
    $e(i) \coloneqq P(\tau_{E} <\infty \mid X_0=i)$
    によって定める．$e(i)$を$e_i$ともかく．
\end{definition}


与えられているのは確率行列$A$と初期分布$\delta_i$のみだから，
$\mathrm{Theorem}\ref{markov_exist}$から，適切な
確率空間を設定すれば少なくとも一つはマルコフ連鎖が存在する．マルコフ連鎖の
取り方によらないことを確かめる．

\begin{theorem}
    この定義はwell-defined，すなわちマルコフ連鎖の取り方には依存しない．
\end{theorem}


\begin{proof}
    $i\in I$が任意に与えられたとする．$(X,A,\delta_{i},P_0)$および
    $(Y,A,\delta_{i},P_{1})$をマルコフ連鎖とする．
    $X$に対する到達時刻を$\tau_{E}^{0}$とかき，到達確率を$e_{0}$とする．
    $Y$に対する到達確率を$\tau_{E}^{1}$とかき，到達確率を$e_{1}$とする．
    \begin{align}
        e_0 (i) &= P_0(\tau_{E}^{0} < \infty \mid X_0 = i) \\
                &= \sum_{n=0}^{\infty} P_0(\tau_{E}^{0} = n \mid X_0 = i) \\
                &= \sum_{n=0}^{\infty} \sum_{i_0 \notin E,\ldots, 
                i_{n-1} \notin E, i_n \in E} P_0(X_0 = i_0,\ldots,X_n = i_n \mid X_0 = i) \\
                &= \sum_{n=0}^{\infty} \sum_{i_0 \notin E,\ldots, 
                i_{n-1} \notin E, i_n \in E} \delta_{i}(i_0) A_{i_0 i_1} \cdots A_{i_{n-1} i_{n}} \\
                &= \sum_{n=0}^{\infty} \sum_{i_0 \notin E,\ldots, 
                i_{n-1} \notin E, i_n \in E} P_1(Y_0 = i_0,\ldots,Y_n = i_n \mid Y_0 = i) \\
                &= \sum_{n=0}^{\infty} P_1(\tau_{E}^{1} = n \mid Y_0 = i)\\
                &= P_1(\tau_{E}^{1} < \infty \mid Y_0 = i) \\
                &= e_1(i)
    \end{align}
    となるから，示された．
\end{proof}


たとえ最初に$P(X_0 = i) = \nu_i = 0$であったとしても，
$\mathrm{Theorem}\ref{markov_prop2}$から，$P(X_m = i)=\nu_i >0$
となる$m \in \N$が存在すれば，
$(Y_n)_{n=0}^{\infty}=(X_{n+m})_{n=0}^{\infty}$を
初期分布が$\delta_i$となるように取り直すことができる．
この定義はこの取り直しを念頭に置いている．


\begin{definition}[差分作用素]
    確率行列$A$が与えられたとする．
    任意の$i \in I$に対し$\sum_{j \in I} A_{ij}f(j)$
    が絶対収束する$f\colon I \to \R$に対し，実数値関数
    $\mathcal{L}f$を対応させる差分作用素$\mathcal{L}$を
    $\mathcal{L}f(i) \coloneqq \sum_{j \in I} A_{ij}f(j) - f(i)$
    によって定める．
\end{definition}


以前に定義した確率ベクトルと確率行列との積は横ベクトルとみてのものであり，
この定義に登場するものとは微妙に異なることに注意する．
次の定理が目標である．


\begin{theorem}[境界値問題]\label{boundary_problem}
    確率行列$A$と$E \subset I$が与えられたとする．
    このとき，到達確率$e$は
    \begin{align}
        \begin{dcases}
            \mathcal{L}e(i) = 0, \quad i \notin E \\
            e(i) = 1, \quad i \in E 
        \end{dcases}
    \end{align}
    を満たす最小の非負実数値関数である．
\end{theorem}


\begin{proof}
    まず$e$が方程式を満たすことを示す．
    $i \in E$のとき$e(i)=1$は
    明らかだから，$i \notin E$とする．
    以下の式中に出てくる$X$は，初期分布が$\delta_{i}$や$\delta_{i_1}$
    で，遷移行列$A$を持つような任意のマルコフ連鎖である．
    \begin{align}
        e(i) &= P(\tau_{E}<\infty \mid X_0 = i) \\
        &= \sum_{n=1}^{\infty} P(\tau_{E} = n \mid X_0 = i) \quad (\because i \notin E)\\
        &= \sum_{n=1}^{\infty} \sum_{i_0 \notin E,\ldots,i_{n-1}\notin E,i_n\in E} 
        P(X_0 = i_0,\ldots,X_n = i_n \mid X_0 = i) \\
        &= \sum_{n=1}^{\infty} \sum_{i_0 \notin E,\ldots,i_{n-1}\notin E,i_n\in E} 
        \delta_{i}(i_0)  A_{i_0 i_1}\cdots A_{i_{n-1} i_n} \quad 
        (\because \mathrm{Theorem}\ref{markov_prop2})\\
        &= \sum_{n=2}^{\infty} \sum_{i_1 \notin E,\ldots,i_{n-1}\notin E,i_n\in E} 
         A_{i i_1} A_{i_1 i_2}\cdots A_{i_{n-1} i_n} 
         + \sum_{i_{1} \in E} A_{i i_{1}} \\
        &= \sum_{n=3}^{\infty} \sum_{i_{1} \notin E} A_{i i_{1}} 
        \sum_{i_2 \notin E,\ldots,i_{n-1}\notin E,i_n\in E} 
        \delta_{i_1}(i_1) A_{i_1 i_2}\cdots A_{i_{n-1} i_n} \\
        &\quad + \sum_{i_{1} \in E} A_{i i_{1}} 
        + \sum_{i_{1} \notin E,i_{2} \in E} A_{i i_{1}} A_{i_{1} i_{2}}\\
        &= \sum_{n=3}^{\infty} \sum_{i_{1} \notin E} A_{i i_{1}}
        \sum_{i_2 \notin E,\ldots,i_{n-1}\notin E,i_n\in E} 
        P(X_0 = i_1,\ldots,X_{n-1} = i_n \mid X_0 = i_1) 
        \quad (\because \mathrm{Theorem}\ref{markov_prop2})\\
        &\quad + \sum_{i_{1} \in E} A_{i i_{1}} P(\tau_{E} <\infty \mid X_0 = i_{1})
        + \sum_{i_{1} \notin E} A_{i i_{1}} P(\tau_{E} = 1 \mid X_0 = i_{1})\\
        &= \sum_{n=3}^{\infty} \sum_{i_{1} \notin E} A_{i i_{1}} 
        P(\tau_{E} = n-1 \mid X_0 = i_1) \\
        &\quad + \sum_{i_{1} \in E} A_{i i_{1}} P(\tau_{E} <\infty \mid X_0 = i_{1})
        + \sum_{i_{1} \notin E} A_{i i_{1}} P(\tau_{E} = 1 \mid X_0 = i_{1})\\
        &= \sum_{i_{1} \notin E} A_{i i_{1}} \sum_{n=2}^{\infty} 
        P(\tau_{E} = n-1 \mid X_0 = i_1) 
        + \sum_{i_{1} \in E} A_{i i_{1}} P(\tau_{E} <\infty \mid X_0 = i_{1})\\
        &= \sum_{i_{1} \notin E} A_{i i_{1}} P(\tau_{E} < \infty \mid X_0 = i_{1})
        + \sum_{i_{1} \in E} A_{i i_{1}} P(\tau_{E} <\infty \mid X_0 = i_{1})\\
        &= \sum_{j \in I} A_{i j} P(\tau_{E} < \infty \mid X_0 = j)\\
        &= \sum_{j \in I} A_{ij} e(j)
    \end{align}
    により示された．最小性を示す．$f \colon I \to \R$を非負実数値関数とし，
    方程式を満たすとする．$e \leq f$を示せばよい．$i \in E$の時は明らかだから，
    $i \notin E$とする．任意の$n \in \N$に対して
    \begin{align}
        f(i) \geq \sum_{k=0}^{n} P(\tau_{E} = k \mid X_0 = i)
    \end{align}
    を示す．帰納法で証明する．$n=0$の時は$i \notin E$より
    $P(\tau_{E} =0\mid X_0 = i) = 0\leq f(i)$となる．$n$までの成立を仮定する．
    \begin{align}
        f(i) &= \sum_{j\in I} A_{ij}f(j) \\
            &\geq \sum_{j \in I} A_{ij} \sum_{k=0}^{n} P(\tau_{E} = k \mid X_0 = j) \\
            &= \sum_{j \notin E} A_{ij} \sum_{k=1}^{n} P(\tau_{E} = k \mid X_0 = j)\\
            &\quad + \sum_{j \in E} A_{ij} \sum_{k=0}^{n} P(\tau_{E} = k \mid X_0 = j) \\
            &= \sum_{j \notin E} \sum_{k=1}^{n} A_{ij}
            \sum_{i_0 \notin E,\ldots,i_{k-1} \notin E,i_{k} \in E}
             P(X_0 = i_0,\ldots,X_k = i_k \mid X_0 = j)\\
            &\quad + \sum_{j \in E} A_{ij}  \\
            &= \sum_{k = 1}^{n} \sum_{j \notin E}  
            \sum_{i_0 \notin E,\ldots,i_{k-1} \notin E,i_{k} \in E}
            A_{ij} \delta_{j}(i_0) A_{i_0 i_1} \cdots A_{i_{k-1} i_{k}} \\
            &\quad + \sum_{j \in E} P(X_0 = i,X_1 = j \mid X_0 = i)  \\
            &=\sum_{k = 2}^{n} \sum_{j \notin E,i_1 \notin E,\ldots,i_{k-1} \notin E,i_{k} \in E}
            A_{ij}  A_{j i_1} \cdots A_{i_{k-1} i_{k}} \\
            &\quad + \sum_{j \notin E,i_1 \in E} A_{ij} A_{j i_1}
            + P(\tau_{E}=1\mid X_0 = i)  \\
            &= \sum_{k = 2}^{n} \sum_{j \notin E,i_1 \notin E,\ldots,i_{k-1} \notin E,i_{k} \in E}
            P(X_0=i,X_1=j,X_2=i_1,\ldots,X_{k+1}=i_k \mid X_0 =i) \\
            &\quad + \sum_{j \notin E,i_1 \in E} P(X_0=i,X_1=j,X_2=i_1 \mid X_0=i) 
            + P(\tau_{E}=1\mid X_0 = i)\\
            &= \sum_{k = 2}^{n} P(\tau_{E} = k+1\mid X_0 = i) 
            + P(\tau_{E} = 2 \mid X_0 = i) + P(\tau_{E}=1\mid X_0 = i)\\
            &= \sum_{k=0}^{n} P(\tau_{E} = k \mid X_0 = i) \quad (\because i \notin E)
    \end{align}
    により，示された．$n \to \infty$として，
    \begin{align}
        f(i) \geq \sum_{n=0}^{\infty} P(\tau_{E}=n \mid X_0 =i) = e(i)
    \end{align}
    となり，示された．
\end{proof}


この定理により，様々な到達確率を求めることができる．
例として，破産問題を扱う．


\begin{example}
    $I = \Z$とし，$X_n$を$n$回目の試行の後の所持金とする．
    $p+q=1$となる非負の実数$p,q$に対して，
    確率$p$で$X_{n+1}=X_{n}+1$とし，確率$q$で$X_{n+1}=X_{n}-1$とするような
    賭けを考える．最初の所持金を$i \in \Z$とすると，初期分布は$\delta_i$で与えられる．
    この試行の確率行列は
    \begin{align}
        A_{ij} = 
        \begin{cases}
            p \quad (j = i + 1) \\
            q \quad (j = i - 1)\\
            0 \quad (\text{それ以外}) 
        \end{cases}
    \end{align}
    によって与えられる．所持金が$0$になった時
    破産したということにして，破産する確率を
    求めたい．$E \subset \Z$を
    $E = \{m \in \Z \mid m \leq 0\}$として，
    $i$から出発して破産する確率は$E$への到達確率$e(i)$で与えられる．
    $\mathrm{Theorem}\ref{boundary_problem}$により
    $e$は
    \begin{align}
        \begin{dcases}
            \mathcal{L}e(i) = 0, \quad i \notin E \\
            e(i) = 1, \quad i \in E 
        \end{dcases}
    \end{align}
    を満たす最小の非負実数値関数である．
    第一式から$i>0$に対して漸化式
    $pe(i+1)+qe(i-1) = e(i)$を得る．
    $e(i+1)-e(i) = (q/p) (e(i) - e(i-1))$と
    変形するなどして，
    \begin{align}
        e(i) =
        \begin{dcases}
            C_0 + C_1 i \quad (p=q) \\
            C_0 + C_1 (q/p)^i \quad (p\neq q)
        \end{dcases}
    \end{align}
    として解くことができる．ここで$C_0,C_1$は定数で，
    非負実数解として最小になるように定める．
    $p \neq q$のときを考える．$e(0)=1$より$C_0 + C_1 = 1$
    であることに注意する．$p <q$ならば，$0 \leq e(i) \leq 1$より
    $C_1=0$となり，$e(i) = 1$となる．したがってどこから出発しても
    必ず破産する．$p > q$ならば$i \to \infty$を考えると
    $e(i) \to C_0 \geq 0$となる．
    よって最小解となるためには$C_0 = 0$が必要で，
    $e(i) = (q/p)^i$となる．
    $p=q$のときは$0 \leq e(i) \leq 1$より$C_1 = 0$となり，$e(i) = 1$
    となる．したがって必ず破産する．
    たとえ公平な賭けとしてもこの場合は必ず破産することが分かった．
\end{example}


\subsection{エルゴード性}
この節では，$I$は有限集合であることを約束する．
これまで見てきた通り確率行列$A$さえ指定すれば
$A$を遷移行列とするマルコフ連鎖のほとんどのことはわかるし，
実際到達確率は遷移行列を用いた方程式で特徴づけられた．
$A$の性質を見れば極限でどうなるのかも分かる．
確率行列の積は確率行列だから，$A^n$も確率行列である．
そこで$A^n$の$i,j$成分を$A_{ij}^n$と書くことにする．


\begin{definition}\label{ergodic}
    $A$を確率行列とする．$A$がエルゴード的とは，ある$n_0 \in \N$が
    存在して，任意の$i,j \in I$に対して$A_{ij}^{n_0}>0$が
    成立することをいう．
    $A$が既約であるとは，任意の$i,j\in I$に対して
    ある$n_1 = n_1(i,j)  \in \N$が存在して$A_{ij}^{n_1} >0$
    が成立することをいう．$i \in I$が$A$について非周期的であるとは，
    ある$n_2= n_2(i) \in \N$が存在して，任意の$n \geq n_2$に対して
    $A_{ii}^{n} > 0$が成立することをいう．
\end{definition}


エルゴード的な確率行列$A$を特徴づける前に，簡単な補題を示す．


\begin{lemma}\label{lem_prod}
    $A,B$を確率行列とする．任意の$i,j \in I$に対して
    $B_{ij}>0$となるとき，任意の$i,j \in I$に対して
    $(AB)_{ij} >0$となる．
\end{lemma}


\begin{proof}
    $i,j \in I$が任意に与えられたとする．
    $\sum_{k \in I} A_{ik} = 1$だから，ある$k_0 \in I$が
    存在して$A_{i k_0}>0$となる．したがって
    $(AB)_{ij} = \sum_{k \in I} A_{ik} B_{kj} \geq A_{ik_0}B_{k_0 j} > 0$
    となり，示された．
\end{proof}


確率行列$A$のエルゴード性を特徴づける定理を述べる．
$I$が有限集合でないと成り立たないことに注意する．


\begin{theorem}
    $A$を確率行列とすると，次は同値．
    \begin{description}
        \item[(1)] $A$はエルゴード的である．
        \item[(2)] $A$は既約，かつ全ての$i \in I$が
        $A$について非周期的である． 
        \item[(3)] $A$は既約，かつある$i_0 \in I$が
        存在して$A$について非周期的である． 
    \end{description}
\end{theorem}


\begin{proof}
    $(1)\Rightarrow (2)$を示す．$A$はエルゴード的だから，
    ある$n_0 \in \N$が存在して，任意の$i,j \in I$に対して$A_{ij}^{n_0}>0$となる．
    $\mathrm{Lemma}\ref{lem_prod}$を$B = A^{n_0}$
    として用いれば，$n \geq n_0$のとき，任意の$i,j \in I$に対して$A_{ij}^n >0$である．
    このことから$(2)$は直ちに従う．
    $(2)\Rightarrow (3)$は明らかである．$(3) \Rightarrow (1)$を示す．
    $i_0 \in I$は$A$について非周期的だから，$n_2 = n_2(i_0) \in \N$が存在して
    $n \geq n_2$ならば$A_{i_{0} i_{0}}^{n}>0$である．$A$は既約だから，任意の
    $i,j \in I$に対し$n_1(i,i_0),n_1(i_0,j) \in \N$が存在して
    $A_{i i_0}^{n_1(i,i_0)} > 0$および$A_{i_0 j}^{n_2(i_0 j)}>0$となる．
    そこで$n_0 \coloneqq \max_{i,j \in I} \{n_1(i,i_0) + n_2(i_0) + n_1(i_0,j)\}$
    と定める．$\mathrm{Lemma}\ref{lem_prod}$を繰り返し用いると，任意の$i,j \in I$に対して，
    $n \coloneqq n_0 - n_1(i,i_0) - n_1(i_0,j) \geq n_2(i_0)$とすると
    $A_{ij}^{n_0} \geq A_{i i_0}^{n_1(i,i_0)} A_{i_0 i_0}^{n} A_{i_0 j}^{n_1(i_0,j)}>0$
    が成立することが分かる．したがって示された．
\end{proof}


エルゴード的な確率行列に対しては不変分布と呼ばれる分布が一意的に存在することを証明する．
補題をいくつか準備する．
\end{document}